{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Rouge Score:\n",
        "\n",
        "- Recall-Oriented Understudy for Gisting Evaluation\n",
        "- for evaluating automatic summarization and machine translation against a reference or a set of references summary or translation\n",
        "- case-sensitive!\n",
        "- compares overlap of n-grams, word sequences and word pairs\n",
        "\n",
        "### Types:\n",
        "1. ROUGE-N\n",
        "2. ROUGE-L\n",
        "3. ROUGE-W\n",
        "4. ROUGE-S"
      ],
      "metadata": {
        "id": "e4oVdahaBWHn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SYxoEHQNBTG9"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def n_grams(text, n):\n",
        "    return [tuple(text[i:i+n]) for i in range(len(text)-n+1)]"
      ],
      "metadata": {
        "id": "em2fe5iYCt-X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_text = \"Rouge Score: A metric for summaries.\"\n",
        "for i in range(1,5):\n",
        "    print(n_grams(random_text, i))\n",
        "    print(len(n_grams(random_text, i)))\n",
        "    print(Counter(n_grams(random_text, i)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9mwZbLSC4e8",
        "outputId": "6ead6e00-f5ff-416b-ec1c-377d738fa10f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('R',), ('o',), ('u',), ('g',), ('e',), (' ',), ('S',), ('c',), ('o',), ('r',), ('e',), (':',), (' ',), ('A',), (' ',), ('m',), ('e',), ('t',), ('r',), ('i',), ('c',), (' ',), ('f',), ('o',), ('r',), (' ',), ('s',), ('u',), ('m',), ('m',), ('a',), ('r',), ('i',), ('e',), ('s',), ('.',)]\n",
            "36\n",
            "Counter({(' ',): 5, ('e',): 4, ('r',): 4, ('o',): 3, ('m',): 3, ('u',): 2, ('c',): 2, ('i',): 2, ('s',): 2, ('R',): 1, ('g',): 1, ('S',): 1, (':',): 1, ('A',): 1, ('t',): 1, ('f',): 1, ('a',): 1, ('.',): 1})\n",
            "[('R', 'o'), ('o', 'u'), ('u', 'g'), ('g', 'e'), ('e', ' '), (' ', 'S'), ('S', 'c'), ('c', 'o'), ('o', 'r'), ('r', 'e'), ('e', ':'), (':', ' '), (' ', 'A'), ('A', ' '), (' ', 'm'), ('m', 'e'), ('e', 't'), ('t', 'r'), ('r', 'i'), ('i', 'c'), ('c', ' '), (' ', 'f'), ('f', 'o'), ('o', 'r'), ('r', ' '), (' ', 's'), ('s', 'u'), ('u', 'm'), ('m', 'm'), ('m', 'a'), ('a', 'r'), ('r', 'i'), ('i', 'e'), ('e', 's'), ('s', '.')]\n",
            "35\n",
            "Counter({('o', 'r'): 2, ('r', 'i'): 2, ('R', 'o'): 1, ('o', 'u'): 1, ('u', 'g'): 1, ('g', 'e'): 1, ('e', ' '): 1, (' ', 'S'): 1, ('S', 'c'): 1, ('c', 'o'): 1, ('r', 'e'): 1, ('e', ':'): 1, (':', ' '): 1, (' ', 'A'): 1, ('A', ' '): 1, (' ', 'm'): 1, ('m', 'e'): 1, ('e', 't'): 1, ('t', 'r'): 1, ('i', 'c'): 1, ('c', ' '): 1, (' ', 'f'): 1, ('f', 'o'): 1, ('r', ' '): 1, (' ', 's'): 1, ('s', 'u'): 1, ('u', 'm'): 1, ('m', 'm'): 1, ('m', 'a'): 1, ('a', 'r'): 1, ('i', 'e'): 1, ('e', 's'): 1, ('s', '.'): 1})\n",
            "[('R', 'o', 'u'), ('o', 'u', 'g'), ('u', 'g', 'e'), ('g', 'e', ' '), ('e', ' ', 'S'), (' ', 'S', 'c'), ('S', 'c', 'o'), ('c', 'o', 'r'), ('o', 'r', 'e'), ('r', 'e', ':'), ('e', ':', ' '), (':', ' ', 'A'), (' ', 'A', ' '), ('A', ' ', 'm'), (' ', 'm', 'e'), ('m', 'e', 't'), ('e', 't', 'r'), ('t', 'r', 'i'), ('r', 'i', 'c'), ('i', 'c', ' '), ('c', ' ', 'f'), (' ', 'f', 'o'), ('f', 'o', 'r'), ('o', 'r', ' '), ('r', ' ', 's'), (' ', 's', 'u'), ('s', 'u', 'm'), ('u', 'm', 'm'), ('m', 'm', 'a'), ('m', 'a', 'r'), ('a', 'r', 'i'), ('r', 'i', 'e'), ('i', 'e', 's'), ('e', 's', '.')]\n",
            "34\n",
            "Counter({('R', 'o', 'u'): 1, ('o', 'u', 'g'): 1, ('u', 'g', 'e'): 1, ('g', 'e', ' '): 1, ('e', ' ', 'S'): 1, (' ', 'S', 'c'): 1, ('S', 'c', 'o'): 1, ('c', 'o', 'r'): 1, ('o', 'r', 'e'): 1, ('r', 'e', ':'): 1, ('e', ':', ' '): 1, (':', ' ', 'A'): 1, (' ', 'A', ' '): 1, ('A', ' ', 'm'): 1, (' ', 'm', 'e'): 1, ('m', 'e', 't'): 1, ('e', 't', 'r'): 1, ('t', 'r', 'i'): 1, ('r', 'i', 'c'): 1, ('i', 'c', ' '): 1, ('c', ' ', 'f'): 1, (' ', 'f', 'o'): 1, ('f', 'o', 'r'): 1, ('o', 'r', ' '): 1, ('r', ' ', 's'): 1, (' ', 's', 'u'): 1, ('s', 'u', 'm'): 1, ('u', 'm', 'm'): 1, ('m', 'm', 'a'): 1, ('m', 'a', 'r'): 1, ('a', 'r', 'i'): 1, ('r', 'i', 'e'): 1, ('i', 'e', 's'): 1, ('e', 's', '.'): 1})\n",
            "[('R', 'o', 'u', 'g'), ('o', 'u', 'g', 'e'), ('u', 'g', 'e', ' '), ('g', 'e', ' ', 'S'), ('e', ' ', 'S', 'c'), (' ', 'S', 'c', 'o'), ('S', 'c', 'o', 'r'), ('c', 'o', 'r', 'e'), ('o', 'r', 'e', ':'), ('r', 'e', ':', ' '), ('e', ':', ' ', 'A'), (':', ' ', 'A', ' '), (' ', 'A', ' ', 'm'), ('A', ' ', 'm', 'e'), (' ', 'm', 'e', 't'), ('m', 'e', 't', 'r'), ('e', 't', 'r', 'i'), ('t', 'r', 'i', 'c'), ('r', 'i', 'c', ' '), ('i', 'c', ' ', 'f'), ('c', ' ', 'f', 'o'), (' ', 'f', 'o', 'r'), ('f', 'o', 'r', ' '), ('o', 'r', ' ', 's'), ('r', ' ', 's', 'u'), (' ', 's', 'u', 'm'), ('s', 'u', 'm', 'm'), ('u', 'm', 'm', 'a'), ('m', 'm', 'a', 'r'), ('m', 'a', 'r', 'i'), ('a', 'r', 'i', 'e'), ('r', 'i', 'e', 's'), ('i', 'e', 's', '.')]\n",
            "33\n",
            "Counter({('R', 'o', 'u', 'g'): 1, ('o', 'u', 'g', 'e'): 1, ('u', 'g', 'e', ' '): 1, ('g', 'e', ' ', 'S'): 1, ('e', ' ', 'S', 'c'): 1, (' ', 'S', 'c', 'o'): 1, ('S', 'c', 'o', 'r'): 1, ('c', 'o', 'r', 'e'): 1, ('o', 'r', 'e', ':'): 1, ('r', 'e', ':', ' '): 1, ('e', ':', ' ', 'A'): 1, (':', ' ', 'A', ' '): 1, (' ', 'A', ' ', 'm'): 1, ('A', ' ', 'm', 'e'): 1, (' ', 'm', 'e', 't'): 1, ('m', 'e', 't', 'r'): 1, ('e', 't', 'r', 'i'): 1, ('t', 'r', 'i', 'c'): 1, ('r', 'i', 'c', ' '): 1, ('i', 'c', ' ', 'f'): 1, ('c', ' ', 'f', 'o'): 1, (' ', 'f', 'o', 'r'): 1, ('f', 'o', 'r', ' '): 1, ('o', 'r', ' ', 's'): 1, ('r', ' ', 's', 'u'): 1, (' ', 's', 'u', 'm'): 1, ('s', 'u', 'm', 'm'): 1, ('u', 'm', 'm', 'a'): 1, ('m', 'm', 'a', 'r'): 1, ('m', 'a', 'r', 'i'): 1, ('a', 'r', 'i', 'e'): 1, ('r', 'i', 'e', 's'): 1, ('i', 'e', 's', '.'): 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_text.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQs2zHvlDlkM",
        "outputId": "34521a8b-c2c2-417f-8128-4fa41ae8e1df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Rouge', 'Score:', 'A', 'metric', 'for', 'summaries.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rouge-N\n",
        "\n",
        "- measures overlap of n-grams between system and reference summaries\n",
        "- Rouge-1: overlap of unigrams\n",
        "- Rouge-2: overlap of bigrams"
      ],
      "metadata": {
        "id": "U2-P9tN7HOFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rouge_n(prediction, reference, n=1):\n",
        "    prediction_tokens = prediction.split()\n",
        "    reference_tokens = reference.split()\n",
        "\n",
        "    prediction_ngrams = Counter(n_grams(prediction_tokens, n))\n",
        "    reference_ngrams = Counter(n_grams(reference_tokens, n))\n",
        "    print(f'Reference Ngrams:\\t{reference_ngrams}')\n",
        "    print(f'Reference Ngrams values:\\t{reference_ngrams.values()}')\n",
        "\n",
        "\n",
        "    print(f'prediction_ngrams & reference_ngrams:{prediction_ngrams & reference_ngrams}')\n",
        "    overlap_ngrams = sum((prediction_ngrams & reference_ngrams).values())\n",
        "    print(f'Overlap Ngrams:\\t{overlap_ngrams}')\n",
        "\n",
        "    total_reference_ngrams = sum(reference_ngrams.values())\n",
        "    print(f'Total reference Ngrams:\\t{total_reference_ngrams}')\n",
        "\n",
        "    if total_reference_ngrams == 0:\n",
        "        return 0.0\n",
        "\n",
        "    recall = overlap_ngrams / total_reference_ngrams\n",
        "\n",
        "    return recall"
      ],
      "metadata": {
        "id": "OLMYgs2LC-T7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_text = \"It was amazing.\"\n",
        "reference_text = \"It was really amazing\""
      ],
      "metadata": {
        "id": "140wr33WEYKl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_n(prediction=prediction_text, reference=reference_text, n=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byhJutXjEU6V",
        "outputId": "7634018e-916e-4b86-e26f-3ca3ecb882bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference Ngrams:\tCounter({('It',): 1, ('was',): 1, ('really',): 1, ('amazing',): 1})\n",
            "Reference Ngrams values:\tdict_values([1, 1, 1, 1])\n",
            "prediction_ngrams & reference_ngrams:Counter({('It',): 1, ('was',): 1})\n",
            "Overlap Ngrams:\t2\n",
            "Total reference Ngrams:\t4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Good Rouge Score\n",
        "\n",
        "- Rouge1: 0.5+\n",
        "- Rouge2: >0.4"
      ],
      "metadata": {
        "id": "mi5VOBnrIcGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rouge-L\n",
        "\n",
        "- based on the length of the Longest Common Subsequence (LCS)\n",
        "- calculates weighted harmonic mean (f-measure)\n",
        "    - combination of recall and precision score\n",
        "\n",
        "- does not require consecutive matches but in-sequence matches\n",
        "\n",
        "\n",
        "#### LCS:\n",
        "- task of finding the longest subsequence that appears in both given sequences in the same order, not necessarily consecutively\n",
        "- does not require the characters to be contiguous, but they must appear in the same order in both sequences.\n",
        "\n",
        "- Subsequences:\n",
        "    - string generated from the original string by deleting 0 or more characters without changing the relative order of the remaining characters\n"
      ],
      "metadata": {
        "id": "7SsxUxYMHYgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lcs(X, Y):\n",
        "    \"\"\"\n",
        "    Function to determine how many characters match as LCS\n",
        "    LCS: Longest Common Subsequence\n",
        "    \"\"\"\n",
        "    m = len(X)\n",
        "    n = len(Y)\n",
        "\n",
        "    # table to store lengths of longest common subsequence\n",
        "    L = [[0] * (n+1) for i in range(m+1)]\n",
        "\n",
        "    for i in range(m+1):\n",
        "        for j in range(n+1):\n",
        "            if i==0 or j==0:\n",
        "                L[i][j] = 0\n",
        "            elif X[i-1] == Y[j-1]:\n",
        "                L[i][j] = L[i-1][j-1] + 1\n",
        "\n",
        "            else:\n",
        "                L[i][j] = max(L[i-1][j], L[i][j-1])\n",
        "\n",
        "    # Backtrack to find the LCS\n",
        "\n",
        "    # length of the string\n",
        "    index = L[m][n]\n",
        "\n",
        "    # random list\n",
        "    lcs_str = [\"\"] * index\n",
        "\n",
        "    i, j = m, n\n",
        "    while i > 0 and j > 0:\n",
        "        if X[i-1] == Y[j-1]:  # If characters match, part of LCS\n",
        "            lcs_str[index-1] = X[i-1]\n",
        "            i -= 1\n",
        "            j -= 1\n",
        "            index -= 1\n",
        "        elif L[i-1][j] > L[i][j-1]:  # Move to the larger value\n",
        "            i -= 1\n",
        "        else:\n",
        "            j -= 1\n",
        "\n",
        "    # print(L)\n",
        "    return L[m][n], \" \".join(lcs_str)"
      ],
      "metadata": {
        "id": "vXz1L21YEiI5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand1 = \"There Many in a number of dogs the park.\"\n",
        "rand2 = \"Many dogs present in the park now.\""
      ],
      "metadata": {
        "id": "WO8IWFi9TxKV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lcs_length, lcs_string = lcs(rand1.split(), rand2.split())\n",
        "lcs_length, lcs_string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mBXWCDqTSzS",
        "outputId": "64ad9125-543d-42dd-a0db-10137c1dea5e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 'Many dogs the')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 1. Recall (R_L):\n",
        "$$\n",
        "R_L = \\frac{LCS(candidate, reference)}{length\\ of\\ reference}\n",
        "$$\n",
        "\n",
        "#### 2. Precision (P_L):\n",
        "$$\n",
        "P_L = \\frac{LCS(candidate, reference)}{length\\ of\\ candidate}\n",
        "$$\n",
        "\n",
        "#### 3. F1 Score (ROUGE-L F1):\n",
        "$$\n",
        "F1 = \\frac{(1+\\beta^2).P_L.R_L}{R_L + \\beta^2.P_L}\n",
        "$$"
      ],
      "metadata": {
        "id": "lzkASVuyeQ9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rouge_l(prediction, reference, beta=1.0):\n",
        "    prediction_tokens = prediction.split()\n",
        "    reference_tokens = reference.split()\n",
        "\n",
        "    lcs_length, lcs_string = lcs(prediction_tokens, reference_tokens)\n",
        "    print(f'Longest common subsequence string is: {lcs_string}')\n",
        "\n",
        "    recall = lcs_length / len(reference_tokens)\n",
        "    precision = lcs_length / len(prediction_tokens)\n",
        "    print(f'Recall={recall:.3f}, Precision={precision}')\n",
        "\n",
        "    if recall+precision==0:\n",
        "        return 0.0\n",
        "\n",
        "    # rouge_l is the f1 score\n",
        "    f1_score = ((1+beta**2) * precision * recall) / (recall * beta**2 * precision)\n",
        "\n",
        "    return f1_score"
      ],
      "metadata": {
        "id": "zF5mZnhjeBtz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_summary = \"the cat is on the mat\"\n",
        "reference_summary = \"the cat is playing on the mat\"\n",
        "rouge_l_score = rouge_l(prediction_summary, reference_summary)\n",
        "\n",
        "print(f'Rouge_l_score = {rouge_l_score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8_2bFj_eqnc",
        "outputId": "0385f74a-1194-496a-dedb-e0c720fc4635"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest common subsequence string is: the cat is on the mat\n",
            "Recall=0.857, Precision=1.0\n",
            "Rouge_l_score = 2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rouge_W\n",
        "\n",
        "- Weighted Longest Common Subsequence\n",
        "- gives more importance to consecutive matches in the sequence\n",
        "- rewards longer consecutive sequences more heavily\n",
        "\n"
      ],
      "metadata": {
        "id": "OwrXKHkEftAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(k):\n",
        "    \"\"\"\n",
        "    Weighting function for consecutive matches.\n",
        "    \"\"\"\n",
        "    return k\n",
        "\n",
        "def weighted_lcs(X, Y):\n",
        "    \"\"\"\n",
        "    Calculates the Weighted Longest Common Subsequence (WLCS) between two strings\n",
        "    \"\"\"\n",
        "    m = len(X)\n",
        "    n = len(Y)\n",
        "\n",
        "    # for scores and lengths of consecutive matches\n",
        "    c = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "    w = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "\n",
        "    max_len = 0\n",
        "    end_idx = 0\n",
        "\n",
        "    # Fill the c and w tables\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "\n",
        "            # If characters match\n",
        "            if X[i - 1] == Y[j - 1]:\n",
        "                k = w[i - 1][j - 1]  # Consecutive match length\n",
        "                c[i][j] = c[i - 1][j - 1] + f(k + 1) - f(k)\n",
        "                w[i][j] = k + 1  # Increase consecutive match length\n",
        "\n",
        "                # Update the maximum WLCS length and position\n",
        "                if c[i][j] > max_len:\n",
        "                    max_len = c[i][j]\n",
        "                    end_idx = i\n",
        "            else:\n",
        "                if c[i - 1][j] > c[i][j - 1]:\n",
        "                    c[i][j] = c[i - 1][j]\n",
        "                else:\n",
        "                    c[i][j] = c[i][j - 1]\n",
        "\n",
        "                # Reset match length\n",
        "                w[i][j] = 0\n",
        "\n",
        "    # Backtrack to find the WLCS string\n",
        "    lcs_str = []\n",
        "    i, j = end_idx, n\n",
        "    while i > 0 and j > 0:\n",
        "        if X[i - 1] == Y[j - 1]:\n",
        "            lcs_str.append(X[i - 1])\n",
        "            i -= 1\n",
        "            j -= 1\n",
        "        elif c[i - 1][j] > c[i][j - 1]:\n",
        "            i -= 1\n",
        "        else:\n",
        "            j -= 1\n",
        "\n",
        "    # Reverse the lcs_str to get the correct order\n",
        "    lcs_str.reverse()\n",
        "\n",
        "    # Return the maximum WLCS score and the corresponding WLCS string\n",
        "    return max_len, ''.join(lcs_str)\n",
        "\n",
        "# Example usage\n",
        "X = \"ABCXYZDEF\"\n",
        "Y = \"XYZABCDEF\"\n",
        "\n",
        "wlcs_length, wlcs_str = weighted_lcs(X, Y)\n",
        "print(\"Weighted LCS length:\", wlcs_length)\n",
        "print(\"Weighted LCS string:\", wlcs_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq8tKwK_jex2",
        "outputId": "ca6b6640-bd04-4c41-b5c4-1e7cd24e5640"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted LCS length: 6\n",
            "Weighted LCS string: XYZDEF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rogue-S (Skip-Bigram Co-Occurrence Statistics)\n",
        "\n",
        "- skip-bigram: pair of words in their sentene order, with arbitrary gaps\n",
        "- computes recall of skip-bigrams by comparing them in generated summary with those in reference summary\n",
        "\n",
        "##### Steps:\n",
        "1. Extract bi-grams\n",
        "2. Calculate overlap\n",
        "3. Compute Rogue-S Score\n",
        "\n"
      ],
      "metadata": {
        "id": "Sg7xmOOBybOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_skip_bigrams(text, max_skip=1):\n",
        "    words = text.split()\n",
        "    skip_bigrams = set()\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        for j in range(i+1, min(i+max_skip+1, len(words))):\n",
        "            skip_bigrams.add((words[i], words[j]))\n",
        "\n",
        "    return skip_bigrams"
      ],
      "metadata": {
        "id": "IRb-u_aC0iSM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand2, get_skip_bigrams(rand2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtmKVjM604AK",
        "outputId": "aa6f3c10-35fb-4792-f2de-e1f3e16ca5b6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Many dogs present in the park now.',\n",
              " {('Many', 'dogs'),\n",
              "  ('Many', 'in'),\n",
              "  ('Many', 'present'),\n",
              "  ('dogs', 'in'),\n",
              "  ('dogs', 'present'),\n",
              "  ('dogs', 'the'),\n",
              "  ('in', 'now.'),\n",
              "  ('in', 'park'),\n",
              "  ('in', 'the'),\n",
              "  ('park', 'now.'),\n",
              "  ('present', 'in'),\n",
              "  ('present', 'park'),\n",
              "  ('present', 'the'),\n",
              "  ('the', 'now.'),\n",
              "  ('the', 'park')})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mathematically,\n",
        "$$\n",
        "Precision=\\frac{No.\\ of\\ overlapping\\ skip-bigrams}{no.\\ of\\ skip-bigrams\\ in\\ prediction}\n",
        "$$\\\n",
        "$$\n",
        "Recall=\\frac{No.\\ of\\ overlapping\\ skip-bigrams}{no.\\ of\\ skip-bigrams\\ in\\ reference}\n",
        "$$\n",
        "\\\n",
        "$$\n",
        "Precision=\\frac{2*Precision*Recall}{Precision + Recall}\n",
        "$$"
      ],
      "metadata": {
        "id": "eU5tLz8Q2bwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rouge_s(prediction, reference, max_skip=1):\n",
        "\n",
        "    prediction_skip_bigram = get_skip_bigrams(prediction, max_skip)\n",
        "    reference_skip_bigram = get_skip_bigrams(reference , max_skip)\n",
        "\n",
        "    # print(f'Reference Ngrams:\\t{reference_skip_bigram}')\n",
        "\n",
        "    overlaps = reference_skip_bigram.intersection(prediction_skip_bigram)\n",
        "    overlaps_count = len(overlaps)\n",
        "    print(f'Overlaps: {overlaps}, Overlaps Count: {overlaps_count}')\n",
        "\n",
        "    # computing precision and recall\n",
        "    if len(prediction_skip_bigram)>0:\n",
        "\n",
        "        precision = overlaps_count / len(prediction_skip_bigram)\n",
        "    else:\n",
        "        precision = 0\n",
        "\n",
        "    if len(reference_skip_bigram)>0:\n",
        "\n",
        "        recall = overlaps_count / len(reference_skip_bigram)\n",
        "    else:\n",
        "        recall = 0\n",
        "\n",
        "    f1_score = (2*precision*recall) / (precision+recall) if (precision+recall)>0 else 0\n",
        "\n",
        "\n",
        "    return f1_score"
      ],
      "metadata": {
        "id": "OrNu2zqiiCUm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_summary = \"the cat is on the mat\"\n",
        "reference_summary = \"the cat is playing on the mat\"\n",
        "rouge_s_score = rouge_s(prediction_summary, reference_summary)\n",
        "\n",
        "print(f'Rouge_S_score = {rouge_s_score:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOLl95TA3HBg",
        "outputId": "8d6c6757-6d45-4546-c85c-07af22a18837"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overlaps: {('cat', 'is'), ('on', 'the'), ('the', 'mat'), ('the', 'cat')}, Overlaps Count: 4\n",
            "Rouge_S_score = 0.727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the functions from library"
      ],
      "metadata": {
        "id": "oHDG2ioM4nUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYSP0cqa5LYT",
        "outputId": "743e0e4d-338e-4a75-9a58-66f41af6163f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rouge"
      ],
      "metadata": {
        "id": "2vp_FQNK6YcV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_ = rouge.Rouge()\n",
        "rouge_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxmE_Hzu4p-r",
        "outputId": "2c2b170c-fe16-46de-fdc5-629989f5b4c5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rouge.rouge.Rouge at 0x78f70af11870>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = rouge_.get_scores(prediction_summary, reference_summary)\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9cE1ton4p7P",
        "outputId": "77949764-763b-4db7-db7f-d1b5662d36b9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'r': 0.8333333333333334, 'p': 1.0, 'f': 0.9090909041322315},\n",
              "  'rouge-2': {'r': 0.6666666666666666, 'p': 0.8, 'f': 0.7272727223140496},\n",
              "  'rouge-l': {'r': 0.8333333333333334, 'p': 1.0, 'f': 0.9090909041322315}}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "self_rouge_l = rouge_l(prediction_summary, reference_summary)\n",
        "self_rouge_l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fkuN_H-8-rO",
        "outputId": "416c4287-5dc8-42af-dff1-3cca3c25b079"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest common subsequence string is: the cat is on the mat\n",
            "Recall=0.857, Precision=1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References:\n",
        "\n",
        "1. [KLU AI Blog](https://klu.ai/glossary/rouge-score)\n",
        "2. [Two minutes NLP](https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499)\n",
        "3. [Github Repo for Rouge Library](https://github.com/pltrdy/rouge/tree/master)"
      ],
      "metadata": {
        "id": "OoWICawXIElg"
      }
    }
  ]
}