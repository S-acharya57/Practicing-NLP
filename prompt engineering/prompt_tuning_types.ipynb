{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5ayY_zzscht"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2H0hJQXssZe_",
    "outputId": "ff2f44cb-de51-4c9c-c609-c71dfb51d90c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.44.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.16)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.38)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.117)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install langchain_community langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HhtvAbIXsk0z"
   },
   "outputs": [],
   "source": [
    "api_key = \"[YOUR-OPEN-API-KEY]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4IW8gLSs_CB"
   },
   "source": [
    "## Chain of Thoughts Prompting\n",
    "\n",
    "- Prefix\n",
    "- Examples\n",
    "- Suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1_Eqnkus8Ij"
   },
   "outputs": [],
   "source": [
    "examples = [\"\"\"\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be based on {context}\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\"\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aEq9xJFtrkn"
   },
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuU6QKU8uGY9"
   },
   "outputs": [],
   "source": [
    "prefix = \"You are a helpful chatbot and answer questions based on provided context only. If the answer to the question is not there in the context, you can politely say that you do not have the answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEThXB1yyflS"
   },
   "outputs": [],
   "source": [
    "query = \"In the unitary method, you first find the value of a single unit by dividing the total value by the number of units, and then multiply that by the required number of units.\"\n",
    "\n",
    "context = \"Example: If 10 apples cost $20, the cost of one apple is $20 divided by 10, which equals $2. Therefore, the cost of 5 apples will be 5 multiplied by $2, equaling $10.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9iEUJAKtSWD",
    "outputId": "6e283b16-f279-4a22-bf5f-d69a02e8f1f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['answer', 'context', 'query'], template='Context:{context}User:{query}AI:{answer}\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_template = \"\"\"Context:{context}User:{query}AI:{answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = langchain.PromptTemplate(\n",
    "    input_variables = [\"context\", \"query\", \"answer\"],\n",
    "    template = example_template\n",
    ")\n",
    "\n",
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VHc3Cy3tuCa",
    "outputId": "c4e5848e-ced8-45c6-a7b2-d2e93d330174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'query'], template='You are a helpful chatbot and answer questions based on provided context only. If the answer to the question is not there in the context, you can politely say that you do not have the answer\\n\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be based on {context}\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\n\\nContext:{context}\\nUser:{query}\\nAI:\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix = \"\"\"\n",
    "Context:{context}\n",
    "User:{query}\n",
    "AI:\n",
    "\"\"\"\n",
    "\n",
    "chat_prompt = langchain.PromptTemplate.from_examples(\n",
    "    examples=examples,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"context\", \"query\"],\n",
    "    prefix=prefix\n",
    ")\n",
    "\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1jnjN3IuI4b",
    "outputId": "f1750e2c-a9bb-4c31-c9f6-4a53415da3c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-34529aac1c5a>:3: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  llm = OpenAI(\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name = \"gpt-3.5-turbo-instruct\",\n",
    "    openai_api_key=api_key,\n",
    "    temperature=0,\n",
    "    max_tokens=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zW3TjO9QuxA5",
    "outputId": "5de58ce0-e191-4eee-cb0f-f4f754b19453"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-deb4441df9ce>:3: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/v0.2/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/v0.2/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag\n",
      "  chain = load_qa_chain(llm,\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "chain = load_qa_chain(llm,\n",
    "                    chain_type=\"stuff\",\n",
    "                    prompt=chat_prompt,\n",
    "                    verbose=False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WmTwk4-vw_z",
    "outputId": "d8c7e595-aa2a-43a9-800f-08440791129c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='In the unitary method, you first find the value of a single unit by dividing the total value by the number of units, and then multiply that by the required number of units.'),\n",
       " Document(page_content='Example: If 10 apples cost $20, the cost of one apple is $20 divided by 10, which equals $2. Therefore, the cost of 5 apples will be 5 multiplied by $2, equaling $10.')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [\n",
    "    langchain.schema.Document(page_content=\"In the unitary method, you first find the value of a single unit by dividing the total \"\n",
    "                          \"value by the number of units, and then multiply that by the required number of units.\",\n",
    "             metadata={}),\n",
    "\n",
    "    langchain.schema.Document(page_content=\"Example: If 10 apples cost $20, the cost of one apple is $20 divided by 10, which equals $2. \"\n",
    "                          \"Therefore, the cost of 5 apples will be 5 multiplied by $2, equaling $10.\",\n",
    "             metadata={})\n",
    "]\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 841
    },
    "id": "rRxnfBSJwC15",
    "outputId": "1428035a-baea-470d-ab59-ee184d9b2843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your unitary method question:\n",
      "If 12 pencils cost $24, how much will 7 pencils cost?\n",
      "Thought: I should first find the value of one pencil\n",
      "Action: Divide the total cost by the number of pencils\n",
      "Action Input: $24 / 12\n",
      "Observation: Each pencil costs $2\n",
      "Thought: Now I can find the cost of 7 pencils\n",
      "Action: Multiply the cost of one pencil by the number of pencils required\n",
      "Action Input: $2 * 7\n",
      "Observation: The cost of 7 pencils is $14\n",
      "Thought: I now know the final answer\n",
      "Final Answer: The cost of 7 pencils will be $14.\n",
      "Enter your unitary method question:\n",
      "If six pencils cost Rs.500 and 3 pens cost Rs.100, how much does 2 pens and 3 pencils cost?\n",
      "Thought: I should first find the value of one pencil and one pen\n",
      "Action: Divide the total cost of pencils by the number of pencils and the total cost of pens by the number of pens\n",
      "Action Input: Rs.500/6 and Rs.100/3\n",
      "Observation: The value of one pencil is Rs.83.33 and the value of one pen is Rs.33.33\n",
      "Thought: Now I can calculate the cost of 2 pens and 3 pencils\n",
      "Action: Multiply the value of one pencil by 3 and the value of one pen by 2\n",
      "Action Input: Rs.83.33*3 and Rs.33.33*2\n",
      "Observation: The cost of 2 pens is Rs.66.66 and the cost of 3 pencils is Rs.249.99\n",
      "Thought: I now know the final answer\n",
      "Final Answer: The cost of 2 pens and 3 pencils is Rs.316.65\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-d27944ba2302>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your unitary method question:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"Enter your unitary method question:\\n\")\n",
    "    try:\n",
    "        response = chain.run(input_documents=docs, query=query)\n",
    "        print(response)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hdt8ysVT2cjk"
   },
   "source": [
    "## Auto-CoT\n",
    "\n",
    "- Automatic Chain of Thoughts\n",
    "\n",
    "* tedious to manually give chains of thoughts, hence automatic\n",
    "\n",
    "2 steps:\n",
    "1. Question Clustering : SentenceBERT used to vectorize the questions as Q\n",
    "2. Demonstration Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tde9PgXN3CgA"
   },
   "source": [
    "## Getting Auto-Cot from Amazon Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGdQ6izVwHrG",
    "outputId": "8874bb71-ac73-4420-bfb1-69a6336f75ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'auto-cot'...\n",
      "remote: Enumerating objects: 83, done.\u001b[K\n",
      "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
      "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
      "remote: Total 83 (delta 40), reused 66 (delta 35), pack-reused 1 (from 1)\u001b[K\n",
      "Receiving objects: 100% (83/83), 36.99 KiB | 3.36 MiB/s, done.\n",
      "Resolving deltas: 100% (40/40), done.\n",
      "/content/auto-cot\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/amazon-science/auto-cot.git\n",
    "%cd auto-cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iuhmp8Vg2-j-",
    "outputId": "ea3358c3-4ae6-42e6-ffcf-9f6aa9792df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn (from -r requirements.txt (line 1))\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvEA3m5E3GLv"
   },
   "source": [
    "## Inference of Auto-Cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbAl_2n63jaq"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "from api import cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IWiiOld33BIU",
    "outputId": "6cebcc33-ed83-4ce8-e4e7-49d34aa016e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Zero shot:\n",
      "*****************************\n",
      "Test Question:\n",
      "There were 10 friends playing a video game online when 7 players quit. If each player left had 8 lives, how many lives did they have total?\n",
      "*****************************\n",
      "Prompted Input:\n",
      "Q: There were 10 friends playing a video game online when 7 players quit. If each player left had 8 lives, how many lives did they have total?\n",
      "A: The answer is\n",
      "*****************************\n"
     ]
    },
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a1266a511055>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquestion\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m\"There were 10 friends playing a video game online when 7 players quit. If each player left had 8 lives, how many lives did they have total?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Example: Zero shot:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zero_shot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/auto-cot/api.py\u001b[0m in \u001b[0;36mcot\u001b[0;34m(method, question)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length_cot\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"cot\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length_direct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"zero_shot_cot\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/auto-cot/utils.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, args, input, max_length)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_for_gpt3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/auto-cot/utils.py\u001b[0m in \u001b[0;36mdecoder_for_gpt3\u001b[0;34m(args, input, max_length)\u001b[0m\n\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         response = openai.Completion.create(\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "question  = \"There were 10 friends playing a video game online when 7 players quit. If each player left had 8 lives, how many lives did they have total?\"\n",
    "print(\"Example: Zero shot:\")\n",
    "cot(method=\"zero_shot\", question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKe5eMveXfkP"
   },
   "source": [
    "## Meta Prompting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prsoMldU_Riu"
   },
   "source": [
    "- prioritizes form and structure over content\n",
    "- uses syntax as fuiding template\n",
    "- assumption of LLM having innate knowledge about the specific task or problem being addressed\n",
    "\n",
    "- categorization of components in prompt\n",
    "    - problem statements\n",
    "    - solution steps\n",
    "    - conclusions\n",
    "\n",
    "\n",
    "### Meta prompting VS Few-shot prompting\n",
    "\n",
    "Meta:\n",
    "\n",
    "    - abstracts problem-solving process itself\n",
    "    - creates prompts that guides model through logical steps to solve problem\n",
    "\n",
    "Few-shot:\n",
    "\n",
    "    - providing LLMs with small number of example problems and their solutions to learn from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RnseD6iI3Wt3"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_eL74R4Htzr",
    "outputId": "bdbd35c3-083c-431d-bf10-b9eb61aa3884"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-b80a49dc506c>:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  llm = langchain.OpenAI(\n"
     ]
    }
   ],
   "source": [
    "llm = langchain.OpenAI(\n",
    "    model_name = \"gpt-3.5-turbo-instruct\",\n",
    "    openai_api_key=api_key,\n",
    "    temperature=0,\n",
    "    max_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDXAb0FLEdT1"
   },
   "outputs": [],
   "source": [
    "meta_prompt = \"\"\"\n",
    "\"Problem\": \"{question}\",\n",
    "\"Solution\": [\"Step 1\":\"Begin the response with \"Let's think step by step.\"\",\n",
    "    \"Step 2\":\"Follow with the reasoning steps, ensuring the solution process is broken down clearly and logically.\",\n",
    "    \"Step 3\":\"End the solution with the final answer encapsulated in a LaTeX-formatted box, ... , for clarity and emphasis.\",\n",
    "],\n",
    "\"Final Answer\":\"[final answer to the problem]\"\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yijVUZCPG8fm",
    "outputId": "4a8428fb-7040-448d-d800-463589ca54f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], template='\\n\"Problem\": \"{question}\",\\n\"Solution\": [\"Step 1\":\"Begin the response with \"Let\\'s think step by step.\"\",\\n    \"Step 2\":\"Follow with the reasoning steps, ensuring the solution process is broken down clearly and logically.\",\\n    \"Step 3\":\"End the solution with the final answer encapsulated in a LaTeX-formatted box, ... , for clarity and emphasis.\",\\n],\\n\"Final Answer\":\"[final answer to the problem]\"\\n    ')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = langchain.PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=meta_prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_wMFgQoHa2F",
    "outputId": "422ef59d-01db-4f24-cac5-b53136655f1d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-4635a3e85d7b>:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FaxKl-0INjh"
   },
   "outputs": [],
   "source": [
    "question = \"What is the derivative of x^2 + 2x with respect to x?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HrJ7tRMIuCg",
    "outputId": "71dad783-ff52-4d05-a089-245286b82534"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-97ee6a1c37b8>:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result = llm_chain.run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated output:\n",
      " \n",
      "Let's think step by step.\n",
      "\n",
      "Step 1: The derivative of a polynomial function is found by multiplying each term by its exponent and then subtracting 1 from the exponent. \n",
      "\n",
      "Step 2: Applying this rule to the given function, we get:\n",
      "\n",
      "$\\frac{d}{dx}(x^2 + 2x) = 2x + 2$\n",
      "\n",
      "Step 3: Therefore, the derivative of $x^2 + 2x$ with respect to $x$ is $\\boxed{2x + 2}$.\n"
     ]
    }
   ],
   "source": [
    "result = llm_chain.run(\n",
    "    {\n",
    "        \"question\":question\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Generated output:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzjojzcIM43Z"
   },
   "source": [
    "### Hence, derivative is solved with meta prompting with step by step procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "py9diz15XR51"
   },
   "source": [
    "## Prompt Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "E6COfy4yXWWN"
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "bRMCx7laYaxb"
   },
   "outputs": [],
   "source": [
    "api_key = \"YOUR-OPENAI-API-KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "kjeznARBXw7V"
   },
   "outputs": [],
   "source": [
    "llm = langchain.OpenAI(\n",
    "    model_name = \"gpt-3.5-turbo-instruct\",\n",
    "    openai_api_key=api_key,\n",
    "    temperature=0,\n",
    "    max_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "lmTj73sEZJPt"
   },
   "outputs": [],
   "source": [
    "initial_prompt = \"\"\"Summarize the key trends in global temperature changes over the past century.\"\"\"\n",
    "follow_up_prompts = [\n",
    "    \"Based on the trends identified, list the major scientific studies that discuss the causes of these changes.\",\n",
    "    \"Summarize the findings of the listed studies, focusing on the impact of climate change on marine ecosystems.\",\n",
    "    \"Propose three strategies to mitigate the impact of climate change on marine ecosystems based on the summarized findings.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "nKFhLBIDYdCY"
   },
   "outputs": [],
   "source": [
    "def prompt_chain(initial_prompt, followup_prompts, llm):\n",
    "\n",
    "    prompt = langchain.PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template=initial_prompt,\n",
    "    verbose=True,\n",
    "    )\n",
    "\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    result = llm_chain.run(\n",
    "        {}\n",
    "    )\n",
    "\n",
    "    for i, followup_prompt in enumerate(follow_up_prompts):\n",
    "        print(f'\\n\\nResult for prompt {i} is:\\n{result}')\n",
    "        new_prompt = f\"{followup_prompt} \\n Previous Output:{result}\"\n",
    "\n",
    "        prompt = langchain.PromptTemplate(\n",
    "        input_variables=[],\n",
    "        template=new_prompt,\n",
    "        verbose=True,\n",
    "        )\n",
    "\n",
    "\n",
    "        llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        result = llm_chain.run(\n",
    "            {}\n",
    "        )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvSbFWuObpwJ",
    "outputId": "6957eb80-b8c2-4622-fb55-1d0b5b07453c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Result for prompt 0 is:\n",
      "\n",
      "\n",
      "1. Overall Increase in Temperature: The most significant trend in global temperature changes over the past century is the overall increase in temperature. Since the late 19th century, the Earth's average temperature has risen by about 1 degree Celsius (1.8 degrees Fahrenheit).\n",
      "\n",
      "2. Acceleration of Temperature Rise: The rate of temperature increase has also accelerated in recent decades. The 20 warmest years on record have all occurred in the past 22 years, with the top four being the last four years.\n",
      "\n",
      "3. Regional Variations: While the global average temperature has been rising, there are regional variations in temperature trends. Some areas, such as the Arctic, have experienced much higher temperature increases than others.\n",
      "\n",
      "4. Warming Oceans: The Earth's oceans have also been warming, with the top 700 meters (2,300 feet) of ocean showing a warming trend of 0.302 degrees Fahrenheit since 1969.\n",
      "\n",
      "5. Decrease in Arctic Sea Ice: The Arctic sea ice has been declining at a rate of 13.3% per decade, with the lowest levels of sea ice recorded in recent years.\n",
      "\n",
      "6. Extreme Weather Events: The increase in global temperature has also been linked to more frequent and severe extreme weather events, such as heatwaves, droughts, and hurricanes.\n",
      "\n",
      "7. Human Influence: The majority of scientists agree that human activities, such as burning fossil fuels and deforestation, are the main cause of the rise in global temperatures.\n",
      "\n",
      "8. Climate Action: In response to the increasing temperatures, there has been a global effort to reduce greenhouse gas emissions and mitigate the effects of climate change. This includes the Paris Agreement, in which countries have committed to limiting global temperature rise to well below 2 degrees Celsius.\n",
      "\n",
      "9. Uncertainty: While there is a clear trend of increasing global temperatures, there is still some uncertainty about the exact extent and impact of future temperature changes.\n",
      "\n",
      "10. Urgent Action Needed: The key trend in global temperature changes over the past century is the urgent need for action to address climate change. Without significant efforts to reduce greenhouse gas emissions, the Earth's temperature will continue to rise, leading to potentially catastrophic consequences for the planet and its inhabitants.\n",
      "\n",
      "\n",
      "Result for prompt 1 is:\n",
      " \n",
      "\n",
      "Major Scientific Studies:\n",
      "\n",
      "1. Intergovernmental Panel on Climate Change (IPCC) Reports: The IPCC is a leading international body for assessing the science related to climate change. Their reports provide comprehensive and up-to-date assessments of the causes and impacts of climate change, as well as potential solutions.\n",
      "\n",
      "2. National Climate Assessment: This report, published by the U.S. Global Change Research Program, provides a comprehensive assessment of the current and projected impacts of climate change on the United States.\n",
      "\n",
      "3. Global Carbon Project: This international research project tracks and analyzes global carbon emissions, providing valuable insights into the main sources of greenhouse gas emissions and their impact on the Earth's climate.\n",
      "\n",
      "4. NASA Goddard Institute for Space Studies (GISS): GISS conducts research on climate change and its causes, using satellite and ground-based observations to monitor changes in the Earth's temperature and other climate indicators.\n",
      "\n",
      "5. National Oceanic and Atmospheric Administration (NOAA): NOAA conducts research on climate change and its impacts, including monitoring changes in ocean temperature and sea ice extent.\n",
      "\n",
      "6. Hadley Centre for Climate Prediction and Research: This UK-based research center conducts studies on climate change and its causes, including the role of human activities and natural factors.\n",
      "\n",
      "7. Climate and Land Use Change (CLUE) Project: This project, led by the University of Maryland, studies the interactions between climate change and land use, including the impact of deforestation on global temperatures.\n",
      "\n",
      "8. Climate Impact Lab: This collaboration between leading research institutions uses data and economic modeling to assess the potential impacts of climate change on different regions and sectors of the global economy.\n",
      "\n",
      "9. Global Climate Observing System (GCOS): GCOS coordinates global observations of the Earth's climate, providing essential data for understanding and monitoring changes in global temperature.\n",
      "\n",
      "10. Climate Science Special Report: This report, published by the U.S. Global Change Research Program, provides a detailed assessment of the current state of climate science, including the causes and impacts of global temperature changes.\n",
      "\n",
      "\n",
      "Result for prompt 2 is:\n",
      " \n",
      "\n",
      "The findings of these studies highlight the significant impact of climate change on marine ecosystems. The IPCC reports and the National Climate Assessment both emphasize the increasing temperatures and ocean acidification caused by rising levels of greenhouse gases, which have negative effects on marine life such as coral bleaching and changes in species distribution. The Global Carbon Project and NASA GISS studies also show the direct link between human activities and the rise in global temperatures, which has a cascading effect on marine ecosystems. The NOAA and Hadley Centre studies focus on the impact of climate change on ocean temperature and sea ice extent, which can have devastating effects on marine species and their habitats. The CLUE Project and Climate Impact Lab highlight the interconnectedness of climate change and land use, with deforestation contributing to both carbon emissions and loss of critical marine habitats. The GCOS provides essential data for monitoring and understanding the changes in global temperature, while the Climate Science Special Report provides a comprehensive overview of the current state of climate science and its implications for marine ecosystems. Overall, these studies demonstrate the urgent need for action to mitigate the effects of climate change on marine ecosystems and protect the delicate balance of life in our oceans.\n",
      " \n",
      "\n",
      "1. Reduce greenhouse gas emissions: The most effective way to mitigate the impact of climate change on marine ecosystems is to reduce the amount of greenhouse gases being emitted into the atmosphere. This can be achieved through various strategies such as transitioning to renewable energy sources, implementing energy-efficient practices, and promoting sustainable transportation methods. By reducing greenhouse gas emissions, we can slow down the rate of global warming and ocean acidification, which will help to protect marine life and their habitats.\n",
      "\n",
      "2. Implement sustainable fishing practices: Overfishing and destructive fishing practices have a significant impact on marine ecosystems. By implementing sustainable fishing practices, we can help to maintain the balance of marine ecosystems and prevent the depletion of fish populations. This can include measures such as setting catch limits, using selective fishing methods, and protecting critical habitats. Sustainable fishing practices also help to reduce the carbon footprint of the fishing industry, which contributes to climate change.\n",
      "\n",
      "3. Protect and restore critical marine habitats: The loss of critical marine habitats, such as coral reefs and mangroves, has a devastating impact on marine ecosystems. These habitats provide essential services such as carbon storage, shoreline protection, and breeding grounds for marine species. By protecting and restoring these habitats, we can help to mitigate the effects of climate change on marine ecosystems. This can be achieved through measures such as creating marine protected areas, reducing pollution and runoff, and implementing sustainable coastal development practices. \n"
     ]
    }
   ],
   "source": [
    "result = prompt_chain(initial_prompt, follow_up_prompts, llm)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4t1Q8nqfnJ0",
    "outputId": "5417190f-ebe8-4fd1-ce88-95bc402b3981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Result for prompt 0 is:\n",
      "\n",
      "\n",
      "1. Globalization and Trade Liberalization: One of the most significant economic trends of the past two decades has been the increasing interconnectedness of global markets. This has been driven by trade liberalization policies, such as free trade agreements and the removal of trade barriers, which have allowed for the free flow of goods, services, and capital across borders.\n",
      "\n",
      "2. Rise of Emerging Markets: The past two decades have seen a significant shift in economic power from developed countries to emerging markets, particularly in Asia. Countries like China, India, and Brazil have experienced rapid economic growth and have become major players in the global economy.\n",
      "\n",
      "3. Technological Advancements: The rapid advancement of technology has had a profound impact on global markets. The rise of the internet and e-commerce has transformed the way businesses operate, making it easier for companies to reach global markets and for consumers to access products and services from around the world.\n",
      "\n",
      "4. Financial Crises: The past two decades have been marked by several major financial crises, including the dot-com bubble burst in 2000, the global financial crisis of 2008, and the Eurozone debt crisis in 2010. These events have had a significant impact on global markets, causing economic downturns and reshaping the global financial system.\n",
      "\n",
      "5. Shift towards Services: There has been a noticeable shift towards services as a major driver of economic growth in many countries. This is due to the increasing importance of the service sector, such as finance, technology, and healthcare, in the global economy.\n",
      "\n",
      "6. Aging Population: Many developed countries, including Japan and European nations, have experienced an aging population over the past two decades. This has had a significant impact on their economies, leading to challenges such as labor shortages and increased healthcare costs.\n",
      "\n",
      "7. Income Inequality: The gap between the rich and poor has widened in many countries over the past two decades. This has been driven by factors such as globalization, technological advancements, and changes in labor markets, leading to social and political implications.\n",
      "\n",
      "8. Environmental Concerns: The past two decades have seen a growing awareness of the impact of economic activities on the environment. This has led to a shift towards sustainable and environmentally-friendly practices in many industries, as well as the emergence of green markets.\n",
      "\n",
      "9. Changing Consumer Behavior: The rise of the internet and social media has changed consumer behavior, with more people shopping online and seeking out personalized and convenient experiences. This has had a significant impact on traditional brick-and-mortar businesses and has led to the growth of e-commerce.\n",
      "\n",
      "10. Shift towards a Knowledge-based Economy: With the rise of technology and the increasing importance of services, there has been a shift towards a knowledge-based economy. This has led to a greater emphasis on education and skills development, as well as the growth of industries such as information technology and research and development.\n",
      "\n",
      "\n",
      "Result for prompt 1 is:\n",
      " \n",
      "\n",
      "Major economic theories or models that explain these patterns include:\n",
      "\n",
      "1. Neoliberalism: This economic theory advocates for free market policies, including trade liberalization and deregulation, which have contributed to the increasing interconnectedness of global markets and the rise of emerging markets.\n",
      "\n",
      "2. Technology-Driven Growth Theory: This theory explains the role of technological advancements in driving economic growth, as seen in the rapid growth of the internet and e-commerce.\n",
      "\n",
      "3. Keynesian Economics: This theory emphasizes the role of government intervention in stabilizing the economy during times of financial crises, as seen in the response to the global financial crisis of 2008.\n",
      "\n",
      "4. Service Sector Growth Theory: This theory explains the shift towards services as a major driver of economic growth, as the service sector becomes increasingly important in the global economy.\n",
      "\n",
      "5. Demographic Transition Theory: This theory explains the impact of an aging population on the economy, including labor shortages and increased healthcare costs.\n",
      "\n",
      "6. Marxist Theory: This theory highlights the role of income inequality in shaping economic trends, as the gap between the rich and poor widens in many countries.\n",
      "\n",
      "7. Environmental Economics: This field of economics focuses on the impact of economic activities on the environment and advocates for sustainable and environmentally-friendly practices.\n",
      "\n",
      "8. Consumer Behavior Theory: This theory explains the changing behavior of consumers, particularly the shift towards online shopping and personalized experiences, and its impact on traditional businesses.\n",
      "\n",
      "9. Knowledge-based Growth Theory: This theory explains the shift towards a knowledge-based economy, as technology and services become increasingly important drivers of economic growth.\n",
      "\n",
      "10. Human Capital Theory: This theory emphasizes the importance of education and skills development in driving economic growth, particularly in a knowledge-based economy.\n",
      "\n",
      "\n",
      "Result for prompt 2 is:\n",
      " \n",
      "\n",
      "Overall, these theories and models highlight the complex and interconnected nature of the global economy. They also emphasize the role of technology, government intervention, demographic changes, income inequality, and consumer behavior in shaping economic trends. \n",
      "\n",
      "In terms of implications for international trade policies, these theories suggest the importance of promoting free trade and technological advancements, while also addressing issues such as income inequality and environmental sustainability. They also highlight the need for governments to invest in education and skills development to support a knowledge-based economy. Additionally, these theories emphasize the need for policies that can adapt to changing consumer behavior and demographic shifts. Overall, a holistic and multifaceted approach to international trade policies is necessary to address the various factors and dynamics at play in the global economy.\n",
      " \n",
      "\n",
      "Based on these findings, the following policy recommendations can be proposed to enhance global economic stability:\n",
      "\n",
      "1. Promote Inclusive Growth: Governments should prioritize policies that promote inclusive growth, addressing income inequality and ensuring that the benefits of economic growth are shared by all segments of society. This can include measures such as progressive taxation, social safety nets, and investment in education and skills development for marginalized communities.\n",
      "\n",
      "2. Encourage Technological Advancements: Governments should support and invest in research and development to promote technological advancements, which can drive economic growth and improve productivity. This can include providing incentives for businesses to innovate and collaborate with research institutions, as well as investing in infrastructure and digital connectivity.\n",
      "\n",
      "3. Foster Sustainable Development: In order to ensure long-term economic stability, policies should prioritize sustainable development and address environmental concerns. This can include implementing regulations and incentives to promote sustainable practices in industries such as energy and agriculture, as well as investing in renewable energy and green infrastructure.\n",
      "\n",
      "Overall, these policy recommendations aim to address the various factors and dynamics at play in the global economy, promoting inclusive and sustainable growth while also fostering technological advancements. By taking a holistic approach and considering the interconnectedness of economic trends, these policies can contribute to enhancing global economic stability.\n"
     ]
    }
   ],
   "source": [
    "# for economic dataset\n",
    "initial_prompt = \"\"\"Analyze the key economic trends and patterns observed in global markets over the past two decades.\"\"\"\n",
    "follow_up_prompts = [\n",
    "    \"Based on the trends identified, identify the major economic theories or models that explain these patterns.\",\n",
    "    \"Summarize the key findings from these theories or models, focusing on their implications for international trade policies.\",\n",
    "    \"Propose three policy recommendations to enhance global economic stability based on the summarized findings.\"\n",
    "]\n",
    "\n",
    "result = prompt_chain(initial_prompt, follow_up_prompts, llm)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDnQ3MZje96j"
   },
   "source": [
    "### Thus, the generation of 3 different prompts with previous output passed as input to the new prompt is implemented with Prompt Chaining."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "p4IW8gLSs_CB",
    "tde9PgXN3CgA",
    "DvEA3m5E3GLv",
    "bKe5eMveXfkP"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
