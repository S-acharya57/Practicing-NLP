# Practicing-NLP

This repository consists of my practice for some foundations related to the NLP domain.

### Data Preprocessing

It consists of preprocessing data, with web scraping using BeautifulSoup. It has implementation of NLTK library for processing them.

### Prompt Engineering

Implementation of different prompt engineering techniques.

- [Simple Implementation](https://github.com/S-acharya57/Practicing-NLP/blob/main/prompt%20engineering/prompt_tuning_types.ipynb) : It consists implementation and inference of Chain of Thought, Auto-Chain of Thought, Meta-Prompting and Prompt Chaining techniques.

- [PAL Prompting](https://github.com/S-acharya57/Practicing-NLP/blob/main/prompt%20engineering/PAL_Prompting.ipynb) : It consists of implementation of Program-Aided Language Models to give solutions like python scripts.

### Transformers

- [Understanding Positional Encoding](https://github.com/S-acharya57/Practicing-NLP/blob/main/Tranformer/positional_encoding.ipynb): This includes simple implementation of positional encoding from scratch and analyzing the values.

- [Attention Implementation](https://github.com/S-acharya57/Practicing-NLP/blob/main/Tranformer/attention.ipynb)

- [Encoder from Scratch](<https://github.com/S-acharya57/Practicing-NLP/blob/main/Tranformer/transformer_encoder(from_scratch).ipynb>)

- [FInetuning BERT](https://github.com/S-acharya57/Practicing-NLP/blob/main/Tranformer/BERT_finetuning.ipynb) : It involves finetuning BERT for Next Word Prediction.

- [BERT With Byte Level Byte Pair Encoding Tokenizer](https://github.com/S-acharya57/Practicing-NLP/tree/main/Tranformer/RoBERTA%20Scratch%20Implementation) : It involves finetuning Roberta model on texts of Immanuel Kant.

### RAG Implementation

- [Chunking and Embedding ](https://github.com/S-acharya57/Practicing-NLP/blob/main/RAGImplementation/chunking_and_embedding.ipynb) : Use of PDF to extract data and chunk and index matching elements based on the query.
- [Implementation of RAG](https://github.com/S-acharya57/Practicing-NLP/blob/main/RAGImplementation/rag.ipynb) : Implementation of RAG using Sentence Transformers, with use of pretrained Google Gemma-2b-it model.
