{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRzKD9hdTVZ8"
      },
      "source": [
        "## Kantai Bert with Byte Level Byte pair Encoding Tokenizer\n",
        "\n",
        "1. Obtaining the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2fNX9iMTc85"
      },
      "source": [
        "### 1. Obtaining the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGIfBaH2TJzb",
        "outputId": "0696feac-a73b-4804-c8d6-44e3dc181981"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0 10.7M    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  1 10.7M    1  128k    0     0  75271      0  0:02:29  0:00:01  0:02:28 75415\n",
            " 31 10.7M   31 3488k    0     0  1273k      0  0:00:08  0:00:02  0:00:06 1274k\n",
            "100 10.7M  100 10.7M    0     0  3393k      0  0:00:03  0:00:03 --:--:-- 3397k\n"
          ]
        }
      ],
      "source": [
        "# dataset of books by Immanuel Kant\n",
        "\n",
        "!curl -L https://raw.githubusercontent.com/PacktPublishing/Transformers-for-Natural-Language-Processing/master/Chapter03/kant.txt --output \"kant.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DxY3CCOETT4y",
        "outputId": "e719381c-3411-4059-e2bb-328b6e2f0516"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall tensorflow\n",
        "# !pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye7esR-kUDD-",
        "outputId": "9391e176-62ba-4f5b-cbcb-6aa61e60f84e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'grep' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# getting versions of transformers and tokenizers\n",
        "!pip list | grep -E 'transformers|tokenizers'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "THHowdEnVRXQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\After\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import tokenizers\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZrKCSNtUWT3",
        "outputId": "8f668317-5ab0-4ef3-af3e-ca76df2647b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['kant.txt']\n",
            "Tokenizer: Tokenizer(vocabulary_size=0, model=ByteLevelBPE, add_prefix_space=False, lowercase=False, dropout=None, unicode_normalizer=None, continuing_subword_prefix=None, end_of_word_suffix=None, trim_offsets=False)\n",
            "CPU times: total: 12.5 s\n",
            "Wall time: 1.25 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# using bytelevelbpetokenizer\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "paths = [str(x) for x in Path(\".\").glob(\"*.txt\")]\n",
        "print(paths)\n",
        "\n",
        "tokenizer = tokenizers.ByteLevelBPETokenizer()\n",
        "print(f'Tokenizer: {tokenizer}')\n",
        "\n",
        "tokenizer.train(files=paths, vocab_size=50000, min_frequency=2, special_tokens=[\n",
        "    \"<start>\",\n",
        "    \"<pad>\",\n",
        "    \"<\\s>\",\n",
        "    \"<unknown>\",\n",
        "    \"<mask>\",\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ15RtZXVu-d",
        "outputId": "47fa0da3-17fd-4e81-cc00-29c40f87c2ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dir made\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Tokenizer\\\\vocab.json', 'Tokenizer\\\\merges.txt']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "tokenizer_dir = 'Tokenizer'\n",
        "\n",
        "# print(os.path.exists(tokenizer_dir))\n",
        "if os.path.exists(tokenizer_dir):\n",
        "    # print(os.path.listdir)\n",
        "    pass\n",
        "\n",
        "if not os.path.exists(tokenizer_dir):\n",
        "    os.mkdir(tokenizer_dir)\n",
        "    print(\"Dir made\")\n",
        "tokenizer.save_model('Tokenizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fbUlN-VV6NX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
